{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/trains/102.csv', sep=';')\n",
    "# Sort by timestamps_UTC\n",
    "timestamp_col = 'timestamps_UTC'\n",
    "data[timestamp_col] = pd.to_datetime(data[timestamp_col])\n",
    "data = data.sort_values(by=timestamp_col)\n",
    "# Remove data when consecutive timestamps delta is bigger than 30min\n",
    "data = data[data[timestamp_col].diff() < pd.Timedelta(minutes=30)]\n",
    "\n",
    "# data[data[data[timestamp_col].diff() > pd.Timedelta(minutes=30)]]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce0fdc645fc44e6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AirTemp = data['RS_E_InAirTemp_PC2']\n",
    "Timestamps = data['timestamps_UTC']\n",
    "\n",
    "ts = pd.Series(AirTemp.values, index=Timestamps)\n",
    "ts = ts[2000:4000]\n",
    "\n",
    "# Normalize the data between 0 and 1\n",
    "ts = (ts - ts.min()) / (ts.max() - ts.min())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e494696dd424a6c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.src.layers import LSTM, TimeDistributed, Dense\n",
    "from keras.src.layers import Dropout\n",
    "from keras.src.layers import RepeatVector\n",
    "from keras import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming normalized_ts is your normalized time series\n",
    "sequence_length = 30\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(values, time_steps=sequence_length):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "# Create sequences\n",
    "x_train = create_sequences(ts)\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(x_train.shape[1], x_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    RepeatVector(x_train.shape[1]),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    TimeDistributed(Dense(x_train.shape[2]))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, x_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Anomaly detection\n",
    "x_train_pred = model.predict(x_train)\n",
    "x_train_pred\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d7b858a28ff125a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect all the samples which are anomalies\n",
    "anomalies = train_mae_loss > 2 * np.std(train_mae_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot anomalies\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ts[sequence_length:].index, ts[sequence_length:], label='AirTemp')\n",
    "plt.plot(ts[sequence_length:].index, train_mae_loss, label='Train MAE loss')\n",
    "plt.plot(ts[sequence_length:].index, anomalies, label='Anomaly')\n",
    "\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(train_mae_loss, label='Train MAE loss')\n",
    "\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdac09954e09a2d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from processing.outliers.moving_average import moving_average\n",
    "from processing.outliers.outliers import compute_outliers\n",
    "\n",
    "# Use moving average to detect outliers\n",
    "window_size = 10\n",
    "# Compute moving average of moving average\n",
    "ts_ma = moving_average(ts, window_size)\n",
    "compute_outliers(ts_ma, ts).plot()\n",
    "\n",
    "# Compute difference between moving average and initial data\n",
    "diff = ts_ma - ts\n",
    "# Compute derivative of difference\n",
    "diff = diff.diff()\n",
    "#Absolute value of derivative\n",
    "diff = diff.abs()\n",
    "# Now plot the original data and the moving average, along with the outliers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ts.index, ts, label='Original data')\n",
    "plt.plot(ts_ma.index, ts_ma, label='Moving average (n=%d)' % window_size)\n",
    "# plot arima\n",
    "\n",
    "# When the derivative is bigger than 0.1, we have an outlier\n",
    "plt.plot(diff[diff > 0.3].index, ts[diff > 0.3], 'ro', label='Outliers')\n",
    "plt.legend(loc='best')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1a5ce5238f5fddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Outliers detection using ARIMA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../assets/trains/102.csv', sep=';')\n",
    "# Sort by timestamps_UTC\n",
    "timestamp_col = 'timestamps_UTC'\n",
    "data[timestamp_col] = pd.to_datetime(data[timestamp_col])\n",
    "data = data.sort_values(by=timestamp_col)\n",
    "# Remove data when consecutive timestamps delta is bigger than 30min\n",
    "data = data[data[timestamp_col].diff() < pd.Timedelta(minutes=30)]\n",
    "\n",
    "# Remove data when 'RS_E_InAirTemp_PC2' is 0\n",
    "data_clean = data[data['RS_E_InAirTemp_PC2'] != 0]\n",
    "\n",
    "AirTemp = data['RS_E_InAirTemp_PC2']\n",
    "Timestamps = data['timestamps_UTC']\n",
    "\n",
    "AirTemp_clean = data_clean['RS_E_InAirTemp_PC2']\n",
    "Timestamps_clean = data_clean['timestamps_UTC']\n",
    "\n",
    "ts = pd.Series(AirTemp.values, index=Timestamps)\n",
    "ts = ts[0:100000]\n",
    "\n",
    "ts_clean = pd.Series(AirTemp_clean.values, index=Timestamps_clean)\n",
    "ts_clean = ts_clean[0:100000]\n",
    "\n",
    "# Normalize the data between 0 and 1\n",
    "ts = (ts - ts.min()) / (ts.max() - ts.min())\n",
    "ts_clean = (ts_clean - ts_clean.min()) / (ts_clean.max() - ts_clean.min())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create one model for the clean data and one for the original data\n",
    "\n",
    "# Fit the model for the original data\n",
    "model = ARIMA(ts, order=(5, 1, 0))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Compute the residuals\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot(label='Residuals')\n",
    "plt.legend()\n",
    "\n",
    "# Fit the model for the clean data\n",
    "model_clean = ARIMA(ts_clean, order=(5, 1, 0))\n",
    "model_fit_clean = model_clean.fit()\n",
    "\n",
    "# Compute the residuals\n",
    "residuals_clean = pd.DataFrame(model_fit_clean.resid)\n",
    "residuals_clean.plot(label='Residuals')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Detect outliers\n",
    "outliers = residuals[abs(residuals[0]) > 0.3]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot the outliers\n",
    "plt.plot(ts.index, ts, label='Original data')\n",
    "plt.plot(outliers.index, ts[outliers.index], 'ro', label='Outliers')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot the outliers for the clean data\n",
    "outliers_clean = residuals_clean[abs(residuals_clean[0]) > 0.3]\n",
    "plt.plot(ts_clean.index, ts_clean, label='Clean data')\n",
    "plt.plot(outliers_clean.index, ts_clean[outliers_clean.index], 'ro', label='Outliers')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
